{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Encoder\n",
    "import org.apache.spark.sql.expressions.Aggregator\n",
    "import org.apache.spark.sql.TypedColumn\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.SQLContext\n",
    "val sqlContext = SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val paidAgg = new Aggregator[(Int, String, Double), (Double, Boolean), Option[Double]] with Serializable {\n",
    "\t/* The initial value */\n",
    "\tdef zero: (Double, Boolean) = (0.0, false)\n",
    "\t\n",
    "\t/* Add an element to the running total */\n",
    "\tdef reduce(b: (Double, Boolean), a: (Int, String, Double)) = \n",
    "\t{\n",
    "\t\tval inc = if (a._2 == \"PAID\") a._3 else 0.0\n",
    "\t\tval isCheckedIn = (a._2 == \"Checked In\")\n",
    "\t\t(b._1 + inc, b._2 || isCheckedIn)\n",
    "\t}\n",
    "\n",
    "\t/* Merge intermediate values */\n",
    "\tdef merge(b1: (Double, Boolean), b2: (Double, Boolean)) = (b1._1 + b2._1, b1._2 || b2._2)\n",
    "\t\n",
    "\t/* Return the final result */\n",
    "\tdef finish(b: (Double, Boolean)) = if (b._2) Some(b._1) else None\n",
    "}.toColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val df = Seq((10, \"Checked out\", 1.0), (10, \"PAID\", 40.0), (10, \"Checked In\", 1.0), (15, \"Flew Away\", 2.0),\n",
    "             (15, \"PAID\", 100.00), (15, \"Came back\", 1.0), (20, \"PAID\", 150.00), (30, \"Checked In\", 1.0), \n",
    "             (30, \"PAID\", 50.00), (30, \"PAID\", 10.00)).toDF(\"CustNum\", \"Action\", \"Val\")\n",
    "\n",
    "val df2 = Seq((10, (\"Checked out\", 1.0)), (10, (\"PAID\", 40.0))).toDF(\"CustNum\", \"Action-Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|CustNum|       Action-Val|\n",
      "+-------+-----------------+\n",
      "|     10|[Checked out,1.0]|\n",
      "|     10|      [PAID,40.0]|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(StructField(CustNum,IntegerType,false), StructField(Action-Val,StructType(StructField(_1,StringType,true), StructField(_2,DoubleType,false)),true))"
     ]
    }
   ],
   "source": [
    "print(df2.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| _1|        _2|\n",
      "+---+----------+\n",
      "| 10|Some(40.0)|\n",
      "| 15|      None|\n",
      "| 20|      None|\n",
      "| 30|Some(60.0)|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.as[(Int, String, Double)].groupBy(_._1).agg(paidAgg).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: unresolved operator 'Aggregate [CustNum#24], [CustNum#24,($anon$1(),mode=Complete,isDistinct=false) AS $anon$1()#618];\n",
       "StackTrace: org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.failAnalysis(CheckAnalysis.scala:38)\n",
       "org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:44)\n",
       "org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:203)\n",
       "org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:50)\n",
       "org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:121)\n",
       "org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:50)\n",
       "org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:44)\n",
       "org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:34)\n",
       "org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:133)\n",
       "org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:52)\n",
       "org.apache.spark.sql.GroupedData.toDF(GroupedData.scala:57)\n",
       "org.apache.spark.sql.GroupedData.agg(GroupedData.scala:213)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:76)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:81)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:109)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:111)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:113)\n",
       "$line226.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:115)\n",
       "$line226.$read$$iwC$$iwC$$iwC.<init>(<console>:117)\n",
       "$line226.$read$$iwC$$iwC.<init>(<console>:119)\n",
       "$line226.$read$$iwC.<init>(<console>:121)\n",
       "$line226.$read.<init>(<console>:123)\n",
       "$line226.$read$.<init>(<console>:127)\n",
       "$line226.$read$.<clinit>(<console>)\n",
       "$line226.$eval$.<init>(<console>:7)\n",
       "$line226.$eval$.<clinit>(<console>)\n",
       "$line226.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:498)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy($\"CustNum\").agg(paidAgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
